---
title: "Hiring_data_teams"
date: 2021-03-11T11:35:05-08:00
draft: true
---

This is one of those posts that I'm writing mostly because I'm still frequently hearing people say they're struggling
with the question of how to interview data people. I've blogged and spoken previously about the misery of being an interviewee, 
so suffice it to say I have a ton of empathy for how awful it is to go through a bad interview process, and how disappointing it is to 
go through a long, grueling interview and not get an offer. 

# How I hire for data teams

After many years in research science, where I watched a lot of science presentations and helped interview
a large number of graduate students and postdocs and faculty (I never counted how many), I'm a big fan
of learning from what other people have done, rather than reinventing the wheel. 

I'm also really an engineer in the way I think about things, which is to say I like to iteratively improve 
on any processes I develop. If it's working, great, don't fix it if it ain't broke. 

But I think we can all agree that *hiring in tech is still a work in progress.* 

So here's my current process, partly based off of what the Product Hackers were doing when I joined them 
at Yahoo, and partly based off my own observations of what has worked well over the last few years,  
and what didn't. 

I'm not saying it's perfect, but I've been happy with the candidates that I've hired, and the teams that I've built. I'm 
always looking for candidates who bring complementary skill sets, and whose personalities work well together. 

I'll also talk a bit about having to miss out on candidates I wanted but couldn't hire for various reasons. 

## How I think about hiring

In my research career, we did a lot of screening. We screened samples of cells or DNA or antibodies almost daily. 
Some of it is just a numbers game, and has to do with sampling. Some of it has to do with how you do your quality assessments. 
This basically boils down to two keys to success:

1) Start with the most diverse population you can get. 
2) Use the right filters.

Here are the things I always prioritize, regardless of the team, though not always in this order. Your needs may be different. 

1) communication skills
2) curiosity
3) work ethic
4) willingness to learn from everyone
5) ability to work independently
6) ability to work with others
7) technical aptitude. 

## Step 1. Outreach: start with the most diverse population you can get. 

• Advertise in diverse networks. Go out and meet people. 

Don't just stick a job ad on the web and wait for people to apply. 

If you're having trouble finding diverse candidates, either you're not looking, or your company is already too homogenous, and 
it sends a message that either a) you haven't prioritized this, or b) you're biased. Maybe both. 

Do think about how your job ad is written. Here's a map of how some common red-flag words sound to many candidates: 

     {'passionate': 'no work-life balance',
      'rockstar': 'elitist',
      'fast-paced': 'highly stressful, disorganized work environment'}

Do break your ad into "essential" and "nice-to-have" skill sets. 

If you're not sure what skills the team needs most, you shouldn't be hiring anyone yet. 

And then: go to meetups. Join slack groups. MEET PEOPLE. Ask around. Be approachable. As hiring manager, you should
take calls with anyone who asks who seems potentially qualified.  


## Step 2. Resumé review

A note here: I have hired people whom I met via a Slack group or a conference and their resumé wasn't the first thing
I knew about them. It's worth thinking about how much the resumé really captures about what a person is like to work with.

• **Content**

Don't get hung up on what schools people went to, what they studied, or where else they've worked.
 
Consider candidates from big companies and small ones, from academia and from industry. 

*Don't assume you can tell much about a person from their resumé alone.* 

The savvy candidate will get someone to help them with formatting, which may help them stand out from the crowd. 
That can help showcase their skills, which is great, but it can also be misleading. 

You'll have to talk to them to find out if there's any substance behind the shine. 

• **Verbosity and layout**

One thing I look at carefully is whether the resumé seems organized. I don't care if they've used bullet points or 
sentences, as long as the communication about what they did is clear.  

If the resumé seems jam-packed with buzzwords, I'm going to drill down on that (a little) in the phone screen. 

If they've been judicious in what they chose to emphasize about their 
past experience, that suggests to me that they're thoughtful and focused on quality (or they had help). 

It's not necessarily a bad thing if they had help with formatting, if anything it suggests they know how to find 
resources for career growth and take advantage of them. And they understand the importance of communication. 

## Step 3. Phone screen

*Answer a deceptively simple question: When would you use SQL vs. python?*

What I'm looking for what I ask this: 

1. Can I understand your answer? Are you able to express your thoughts clearly? 
2. Does your answer make sense? Are you able to give examples to support your reasoning? 
3. Are you familiar with these tools? Are you honest about your experience level if you've used one more 
than the other, and are you thoughtful about how that affects your choices?

*Tell me about a project you did, or a job you had where you learned something.*

Talking about past projects is best, but that only works well for senior people, 
and it also takes some experience as the interviewer.

To really do it well and make it fair, you have know what to ask, what to listen for, 
when to dig into something someone mentions in passing, etc. 

Otherwise it can be too biased toward people who are particularly outgoing, 
self-promoting, well-rehearsed, not nervous, or just more like you than the other candidates.

So if you're going to take this approach, try to keep some structure around it to make it easier to 
compare across candidates. 

Here are the basics I try to cover, and some people need more prompting than others:

1. What was the business problem you were trying to solve?
2. What approaches did you consider? 
3. Where did the data come from? 
4. What did you end up doing? 
5. Who else worked on this project with you? How was the work divided?
6. What was the end result of your project? Was it successful? How could you tell? 
7. What would you do differently if you could do it over again? 
8. What did you like best and least about this project?

You'll notice that the better candidates can communicate at both high and low levels, that is, 
they can talk about the big picture and business impact, as well as discussing the technical details, 
trade-offs of the choices they made, and think critically about what could've gone better. 

----
Having said all that, if you have to hire very junior people, that's not going to work. They won't 
have projects they can talk about that are directly relevant to the role, or they will have been mostly
just following directions. In those cases, it's hard to get a sense for their work ethic, 
and whether they can work well with others, or handle responsiblity. 

*Story time*: I remember interviewing a technicians for one lab I worked in. We didn't have any 
candidates (college students or recent graduates) who had experience with breeding, feeding, and otherwise maintaining
Xenopus Laevis. I ended up asking people about their previous work experience of all kinds. 

I hired one student who had worked with her parents, who owned a Subway sandwich shop. She was
prompt and efficient, took notes, referred back to her own notes frequently, and communicated clearly. 
She learned quickly, asked great questions, and was enthusiastic about trying new things and taking on responsibility. 

I had another student who was super enthusiastic, but her notes were so bad they were basically 
useless. She had done a lot of volunteer work with kids, so she was good at thinking on her feet, but didn't
enjoy the methodical aspect of working at a bench. 

My advisor at the time also hired a guy who had worked in a pet shop. 
On paper, he was perfectly qualified to help take care of the frogs, but in practice, 
he was kind of disorganized and unreliable, and unwilling to 
take on much responsibility without our having to nag him, for example, 
to keep on top of things that were part of his job, like ordering supplies.  

Point being, think carefully about what qualities you want for the role, and what the team needs,
and interview accordingly. 

More on this in the section about building teams. 

## Step 4a. Take-home (or code pairing, though no one has chosen that when I offered it)

I should mention here, because I almost forgot to include it, that I give the candidate
multiple days to work on the take-home, even though I only expect them to spend a couple of hours on it. 
Part of the idea here is that they can work at their convenience. 

It's supposed to be sort of like a real, though brief, work experience. It's open-book. 
I ask them to disclose any resources they used (stack overflow, asking friends, etc. are all fine). 

This part is important: I schedule a phone call in the middle of the take-home. 
This is another trick I learned from my team at Yahoo. 

I give the candidate time to look over the data, and maybe start working, 
and I encourage them to come up with questions to ask me. 

I've never hired anyone who had zero questions during that phone call. 

I have had one or two people refuse to do a take-home, and they also turned down a 
live code-pairing option. 

• **Tiered approach**

The best interview questions work for candidates at all levels. More senior candidates will make it further and their
answers will be more sophisticated, but ideally we still want to level-set with a series of assessments. So I use the same 
take-home question for everyone, though I re-do it for each company. 

Note: always use real (sanitized) data, which is relevant for the job. Trick questions are the wrong filter. 

• **Structured data**

The most basic level for a data person is, can they handle structured data, and extract information from it. Everyone should
be able to do this, from an entry-level analyst to a senior machine-learning engineer or data engineer. 

I always give them total freedom to use whatever tools are within the realm of things we typically use on the team - 
usually that would be vanilla python, pandas, SQL, scala, or java. Maybe R or Julia if that's really all they know how to use. 
Depends on the role and the team. 

I start by giving them a CSV, usually a time series of some kind, and their task is to clean the data, 
answer some basic questions about it, and then tell me a data story (see below) about what they observed. This part should be fun! 

They can build models if they want, but it's not required. 

I try to choose data sets that I think are representative of
the types of things we see, and I sometimes use a trick that my team at Yahoo used, which is to dirty up the data a bit on purpose. 
Maybe drop some rows, mangle a couple of dates, just to give them some things to work with. 

This part shouldn't take more than an hour. 

• **Summary statistics**

At a minimum, I expect everyone from analyst to data scientist to engineer should be able to use the right summary statistics. 
They should know the difference between a median and a mean, and why it matters. I explicitly ask them to answer some of these
kinds of questions, again just for level setting, and to demonstrate that they can follow directions. 

For a more senior person, this should be trivial. I'm not quizzing them on statistics jargon or anything like that (I personally 
have a terrible memory for that sort of thing anyway), I want to know if they understand the _concepts_, and if they can reason
and communicate about things like the size of the data set, how they would divide up subsets of the data and why. 

• **Room to tell a story**

I want to hire people who can think creatively, and dig deeper, without my having to tell them what to do
every step of the way. This doesn't require a ton of experience, although it can help. Mostly it requires
curiosity. 

It's really important to me that everyone on the team can:
 
1) frame what questions they thought of while they were exploring data and/or cleaning data, 
2) the steps they took to answer those questions, 
3) what they learned. Were they surprised by the results? Why or why not? 

This could be as simple as "I initially assumed that the data set only covered March, but 
when I checked, I saw that there are a couple of days in April, so I had to group the 
summary statistics differently than I did at first."

Or it might be something like "I wanted to see what features were predictive of xyz, so I built a model"

Or it might be a bunch of data visualizations. 

Or all of the above. 

Ideally, I want a team where everyone sees different sides of the elephant. 


• **Unstructured data**

For more senior candidates or people coming from more of a software engineering/computer science 
background, I also include a sample of unstructured data. 

This might be a file with a bunch of log lines, or a json file that isn't entirely consistent with 
some nested fields, or in one case, I used the paginated output from a particular type of database that
included multiple kinds of messy stuff. 

I always choose something that I was able to clean up and analyze in an hour or less. 

In this case, I'm looking for all the same things as above, plus I care a lot more about the code. 
I want to see logging, tests, error handling. 

This has turned out to be a great litmus test for candidates with more coding experience, because there are
so many different ways to parse a file. 

I had a couple of people who used a dead-letter box for bad rows. 

I had one person who contacted me to ask which fields mattered, before unpacking everything (I really really 
wanted to hire her, but she ended up going elsewhere). 

I had one person who wrote some perfectly decent code, but just blindly unpacked and 
included everything in the input file (that was a no-hire). 

Not everyone does the unstructured data part. I leave it up to the candidate whether they want to try it. 

## Step 4b. Review the take-home and do a follow-up phone call. 

I always do a phone call when I'm done reviewing the take-homes, to give the person a chance to tell me 
what they liked or didn't like, what was hard or easy, and what they spent the most time on. 

I've found this is really useful for improving the take-home, and helps me decide who to move onto 
the next stage. 

By this point I'll have had 3 phone calls with each candidate, on 3 different days, so even if each call is only 15 minutes, 
it's not a huge time commitment, and it's really worthwhile for me to get to know them a little better. 

## Step 5. Presentation

If the take-home looks good, I'll ask them to do a video call to present their work. 

This step is critical for weeding out cheaters, and seeing how the candidate deals with being asked
questions or offered feedback. 

I've had the person explode with anger when I asked something along the lines of "I see you did xyz, did you consider
abc instead?" That didn't make a great first impression. 

I've had the person who seemed unable to talk through what their own code was doing, even with help, and 
was genuinely surprised and confused when we pointed out some pretty egregious logical errors. 

Ultimately, I'm looking for confirmation that people did their own work, and even if they had help (which is fine), 
they can explain the code they ended up using. 

• **1:1 with me for more junior people**

One of the mistakes I made in the past was having the candidate present for 2 or more people. 
This is too much for junior folks, they get pretty freaked out and tend to underperform. 

• **For the whole team if they're more senior**

If the candidate is more experienced and they don't have a phobia of public speaking, I'll ask them to 
walk the whole team through their findings. More experienced candidates will make slides anyway, and they're
usually happy to discuss their reasoning, their approaches, and their insights. If they're really 
outstanding, we might include this as part of the "onsite".


## Step 6. "Onsite" aka "meet more people + some other stuff"

• Fill the gaps from the take-home

• See how they talk with nontechnical stakeholders

• Code review exercise

## Successes: How this process correlates with on-the-job performance

• People who did well on the interview actually did better on the job. No one did worse. 

• Building a team with a diverse set of talents. 

## Failures: people I couldn't hire

• Unintentionally terrified the candidate, more than once. 

• Lost a candidate I really wanted because she got a better offer. 

• Lost a candidate because I went along with a company process that I knew would not set her up for success. 

## Building Teams
